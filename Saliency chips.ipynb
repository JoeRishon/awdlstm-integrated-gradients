{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import fastai.train\n",
    "import pandas as pd\n",
    "from captum.attr import LayerIntegratedGradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a fast.ai `Learner` trained to predict IMDB review category `[negative, positive]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "awd = fastai.train.load_learner('.','imdb_fastai_trained_lm_clf.pth')\n",
    "awd.model[0].bptt = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting to the actual layer that holds embeddings\n",
    "embedding_layer = awd.model[0]._modules['module']._modules['encoder_dp']\n",
    "\n",
    "# working around the model prediction - first output only, apply softmax\n",
    "forward_func = lambda x: torch.softmax(awd.model(x)[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make integrated gradients instance\n",
    "lig = LayerIntegratedGradients(\n",
    "    forward_func, \n",
    "    embedding_layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributions_for_sentence(sentence = 'Best film ever', \n",
    "                                  awd_model=awd, \n",
    "                                  lig_instance=lig,\n",
    "                                  target = None, \n",
    "                                  lig_n_steps = 200,\n",
    "                                  baseline_token='.'):\n",
    "    awd = awd_model\n",
    "    lig = lig_instance\n",
    "    vocab = awd.data.x.vocab\n",
    "    sentence_tokens = awd.data.one_item(sentence)[0]\n",
    "    reversed_tokens = [vocab.itos[w] for w in sentence_tokens[0]]\n",
    "    baseline = torch.ones_like(sentence_tokens) * vocab.stoi[baseline_token] # see \"how to choose a good baseline\"\n",
    "    baseline[0,0] = vocab.stoi['xxbos'] # beginning of sentence is always #1\n",
    "    y = awd.predict(sentence)\n",
    "    if target is None:\n",
    "        target = y[1].item()\n",
    "    attrs = lig.attribute(sentence_tokens, baseline, target, n_steps=lig_n_steps)\n",
    "    a = attrs.sum(-1)\n",
    "    a = a / torch.norm(a)\n",
    "    return (\n",
    "        pd.Series(a.numpy()[0], index=reversed_tokens),\n",
    "        y\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://www.imdb.com/review/rw5384922/?ref_=tt_urv\n",
    "review_1917 = \"\"\"\n",
    "I sat in a packed yet silent theater this morning and watched, what I believe to be, the next Academy Award winner for the Best Picture. I'm not at all a fan of war movies but I am a fan of great movies... and 1917 is a great movie. I have never been so mesmerized by set design and direction, the mass human emotion of this film is astonishingly captured and embedded magically in the audience. It keeps running through my mind...the poetry and beauty intertwined with the raw misery of war. Treat yourself... see this movie!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.imdb.com/review/rw5384922/?ref_=tt_urv\n",
    "review_1917 = \"\"\"\n",
    "I sat in a packed yet silent theater this morning and watched, what I believe to be, the next Academy Award winner for the Best Picture.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions, prediction = get_attributions_for_sentence(review_1917, baseline_token='\\n \\n ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ipyvuetify installation:\n",
    "\n",
    "https://github.com/mariobuikhuizen/ipyvuetify/#installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvuetify as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chip(v.Chip):\n",
    "    positive = '0, 255, 0'\n",
    "    negative = '255, 0, 0'\n",
    "    def __init__(self, word, attribution):\n",
    "        direction = self.positive if attribution >= 0 else self.negative\n",
    "        color = f'rgba({direction}, {abs(attribution):.2f})'\n",
    "        super().__init__(class_='mx-0 px-1', \n",
    "                         children=[word], color=color, \n",
    "                         value=attribution,\n",
    "                         label=True, small=True)\n",
    "        \n",
    "def saliency_chips(attributions:pd.Series) -> v.ChipGroup:\n",
    "    children = [Chip(w, a)\n",
    "           for w, a in attributions.iteritems()]\n",
    "    return v.ChipGroup(column=True, children=children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3df1a61041d4e438c2656e20dd29909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ChipGroup(children=[Chip(children=['xxbos'], class_='mx-0 px-1', color='rgba(0, 255, 0, 0.00)', label=True, smâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "saliency_chips(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
