{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ipyvuetify==1.3.0\n",
      "ipywidgets==7.5.1\n",
      "voila==0.1.21\n",
      "torch==1.4.0\n",
      "fastai==1.0.60\n",
      "captum==0.2.0\n",
      "pandas==1.0.3\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fastai.train\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "\n",
    "# --- Model Setup ---\n",
    "\n",
    "# Load a fast.ai `Learner` trained to predict IMDB review category `[negative, positive]`\n",
    "awd = fastai.train.load_learner(\".\", \"imdb_fastai_trained_lm_clf.pth\")\n",
    "awd.model[0].bptt = 200\n",
    "\n",
    "# getting to the actual layer that holds embeddings\n",
    "embedding_layer = awd.model[0]._modules[\"module\"]._modules[\"encoder_dp\"]\n",
    "\n",
    "# working around the model prediction - first output only, apply softmax\n",
    "forward_func = lambda x: torch.softmax(awd.model(x)[0], dim=-1)\n",
    "\n",
    "# make integrated gradients instance\n",
    "lig = LayerIntegratedGradients(forward_func, embedding_layer)\n",
    "\n",
    "# Explainer logic\n",
    "\n",
    "\n",
    "def get_attributions_for_sentence(\n",
    "    sentence,\n",
    "    awd_model=awd,\n",
    "    lig_instance=lig,\n",
    "    target=None,\n",
    "    lig_n_steps=200,\n",
    "    baseline_token=\"\\n \\n \",\n",
    "):\n",
    "    awd = awd_model\n",
    "    lig = lig_instance\n",
    "    vocab = awd.data.x.vocab\n",
    "    sentence_tokens = awd.data.one_item(sentence)[0]\n",
    "    reversed_tokens = [vocab.itos[w] for w in sentence_tokens[0]]\n",
    "    baseline = (\n",
    "        torch.ones_like(sentence_tokens) * vocab.stoi[baseline_token]\n",
    "    )  # see \"how to choose a good baseline\"\n",
    "    baseline[0, 0] = vocab.stoi[\"xxbos\"]  # beginning of sentence is always #1\n",
    "    y = awd.predict(sentence)\n",
    "    if target is None:\n",
    "        target = y[1].item()\n",
    "    attrs = lig.attribute(sentence_tokens, baseline, target, n_steps=lig_n_steps)\n",
    "    a = attrs.sum(-1)\n",
    "    a = a / torch.norm(a)\n",
    "    return (pd.Series(a.numpy()[0], index=reversed_tokens), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.imdb.com/review/rw5384922/?ref_=tt_urv\n",
    "review_1917 = \"\"\"I sat in a packed yet silent theater this morning and watched, what I believe to be, the next Academy Award winner for the Best Picture.\"\"\"\n",
    "\"\"\"I'm not at all a fan of war movies but I am a fan of great movies... and 1917 is a great movie. I have never been so mesmerized by set design and direction, the mass human emotion of this film is astonishingly captured and embedded magically in the audience. It keeps running through my mind...the poetry and beauty intertwined with the raw misery of war. Treat yourself... see this movie!\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvuetify as v\n",
    "import ipywidgets as w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chip(v.Chip):\n",
    "    positive = \"0, 255, 0\"\n",
    "    negative = \"255, 0, 0\"\n",
    "\n",
    "    def __init__(self, word, attribution):\n",
    "        direction = self.positive if attribution >= 0 else self.negative\n",
    "        color = f\"rgba({direction}, {abs(attribution):.2f})\"\n",
    "        super().__init__(\n",
    "            class_=\"mx-0 px-1\",\n",
    "            children=[word],\n",
    "            color=color,\n",
    "            value=attribution,\n",
    "            label=True,\n",
    "            small=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def saliency_chips(attributions: pd.Series) -> v.ChipGroup:\n",
    "    children = [Chip(w, a) for w, a in attributions.iteritems()]\n",
    "    return v.ChipGroup(column=True, children=children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9d808d007c48eab5c2c63df5547684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='I sat in a packed yet silent theater this morning and watched, what I beâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@w.interact_manual(\n",
    "    sentence=w.Textarea(review_1917),\n",
    "    target=[None, 0, 1],\n",
    "    baseline_token=[\"\\n \\n\", \".\", \"<BOS>\"],\n",
    ")\n",
    "def display_attributions(sentence=\"Great film\", target=None, baseline_token=\"\\n \\n \"):\n",
    "    \n",
    "    attributions, prediction = get_attributions_for_sentence(sentence)\n",
    "    \n",
    "    return saliency_chips(attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}